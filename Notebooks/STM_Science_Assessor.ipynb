{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STM Science Assessor\n",
    "This notebook aims to ingest a table of source/observation specs with their achievability rating per detector model (as generated by prior notebook, the Observation Targets Assessor), and convolve with the Science STM objectives, each of which involves one or more of those source/observation specs. The output should be a similar table to the input, but with the source/observvation specs replaced by objectives.\n",
    "\n",
    "To run this on Google Colab:\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnGBaker/GWI-metrics/blob/main/Notebooks/STM_Science_Assessor.ipynb)\n",
    "\n",
    "### Some basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !git clone https://github.com/JohnGBaker/GWI-metrics.git\n",
    "    src='GWI-metrics/src/'\n",
    "else:\n",
    "    src='../src/'\n",
    "!mkdir -p '../plots/'\n",
    "\n",
    "# Import\n",
    "import os\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(src)\n",
    "import constants\n",
    "import metrics\n",
    "import sources\n",
    "import concepts\n",
    "import subsystems\n",
    "import background\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "from glob import glob\n",
    "import re\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from astropy import units as u\n",
    "\n",
    "LARGENUM = 1.0e10 # This is a hard-coded number to beat\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the set of concepts\n",
    "Here we load in a set of the pre-defined concepts, or you can define your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missionNames = (\n",
    "    'LISACBE',\n",
    "    'LISASciRDv1',\n",
    "    'TwinLISA',\n",
    "    'LISAGrande',\n",
    "    'LISAU',\n",
    "    'GoBIGLISA',\n",
    "    'ALIA',\n",
    "    'ALIAlowL')\n",
    "missions=[concepts.menu[mission] for mission in missionNames]\n",
    "\n",
    "Nmissions = len(missionNames)\n",
    "\n",
    "for mission in missions:\n",
    "    mission=background.add2model(mission)\n",
    "#model = concepts.LISACBE.copy()\n",
    "#modelName = model.get('label')\n",
    "#model = background.add2model(model)     # add galactic background model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the observation target data\n",
    "Load information about the target sources and the observation quality targets from the STM.\n",
    "The data are from https://nasa.sharepoint.com/:x:/t/GravitationalWaveImager/EaaeMC7L-2NJpFCQloYbSnoBDZag_cvFWR5_BjRoFAD6Tw?e=uWr4mU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the most recent spec file produced by other Notebook:\n",
    "datadir='../Data/'\n",
    "files=glob(datadir+'ScoredObservations_net_*.csv')\n",
    "files.sort(key=os.path.getmtime)\n",
    "specfile=files[-1]\n",
    "print('Most recent specs file is:',specfile)\n",
    "\n",
    "# Are objective names actually stored?\n",
    "# A: not originally -- had to re-run earlier notbook with the \"index=None\" removed from the CVS save command\n",
    "\n",
    "speclist = []\n",
    "with open(specfile) as f:\n",
    "    for row in f:\n",
    "        speclist.append(row.split(\",\")[0])\n",
    "\n",
    "speclist.pop(0) # remove the top item, which is empty \"corner\" element of table\n",
    "print(\"specs are: \",speclist)\n",
    "\n",
    "Nspecs = len(speclist)\n",
    "\n",
    "#specarray = np.loadtxt(specfile,delimiter=',',skiprows=1,usecols = range(1,Nmissions+1))\n",
    "\n",
    "rawspecarray = np.genfromtxt(specfile,delimiter=',')\n",
    "\n",
    "specarray=rawspecarray[1:Nspecs+1,1:Nmissions+1]\n",
    "#print(\"first row of specarray is \",specarray[0,])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STMfiles=glob('../Data/ScienceSTM*.csv')\n",
    "STMfiles.sort(key=os.path.getmtime)\n",
    "file=STMfiles[-1]\n",
    "#file=glob('../Data/ScienceSTM*.csv')[0]\n",
    "print('Science STM file is:',file)\n",
    "\n",
    "#Read file\n",
    "df=pd.read_csv(file,header=1)\n",
    "print(len(df),'rows read from file.')\n",
    "\n",
    "if True:\n",
    "    #Drop empty rows\n",
    "    for i,row in df.iterrows():\n",
    "        if row.isnull().all():\n",
    "            df=df.drop(i)\n",
    "    #Fill empties in first column with values above\n",
    "\n",
    "    nrows = len(df. index) \n",
    "\n",
    "    newdata = np.zeros((nrows,Nmissions))\n",
    "\n",
    "    val=float('nan')\n",
    "    \n",
    "    col='Astrophysical Parameters (Level 1 Measurement Req)'\n",
    "    requirementNames=df[col].values\n",
    "    if verbose:\n",
    "        print(\"requirement Names are \",requirementNames)\n",
    "\n",
    "    analysisVal=float('nan')\n",
    "    analysisCol='Specific Analyses'\n",
    "    analysisNames=df[analysisCol].values\n",
    "\n",
    "    if verbose:\n",
    "        print(\"analyses are: \",analysisNames)\n",
    "    \n",
    "    analysisCodes = analysisNames\n",
    "    for j in range(len(analysisNames)):\n",
    "        analysisName_here = analysisNames[j]\n",
    "        #print(\"this analysis names is \",analysisName_here)\n",
    "        #found = re.search(\"\\w\\w-\\w\\w\",analysisName_here).group(1)\n",
    "        found = re.findall(\"\\w\\w-\\w\\w\",analysisName_here)\n",
    "        #print(\"analysis Name \",analysisName_here,' has code ',found[0])\n",
    "        analysisCodes[j] = found[0]\n",
    "        \n",
    "    actionVal=float('nan')\n",
    "    actionCol='Science Actions'\n",
    "    actionNames=df[actionCol].values\n",
    "\n",
    "    cleanedList = [x for x in actionNames if str(x) != 'nan']\n",
    "    actionNames = cleanedList\n",
    "    actionCodes = actionNames\n",
    "    for j in range(len(actionNames)):\n",
    "        actionName_here = actionNames[j]\n",
    "        found = re.findall(\"\\w\\w-\\w\",actionName_here)\n",
    "        actionCodes[j] = found[0]\n",
    "    if verbose:\n",
    "        print(\"actions are: \",actionNames)        \n",
    "        print('action codes are: ',actionCodes)\n",
    "    \n",
    "    useAnalysis = np.full(len(analysisCodes),False)\n",
    "    \n",
    "    for i,row in df.iterrows(): #each row should be a specific analysis in analysisNames\n",
    "        if row.isnull()[col]:\n",
    "            val = ''\n",
    "            #df.loc[i,col]=val\n",
    "        else:\n",
    "            val=df.loc[i,col]\n",
    "\n",
    "        if row.isnull()[analysisCol]:\n",
    "            df.loc[i,analysisCol]=analysisVal\n",
    "        else:\n",
    "            analysisVal=df.loc[i,analysisCol]    \n",
    "            \n",
    "        bestspecres_here = LARGENUM*np.ones(Nmissions)\n",
    "\n",
    "        # parse to get values in form of 2.3.b == <single digit> + dot + <single digit> + dot + <single letter>\n",
    "        # or perhaps just a comma-separated list that can be compared with other file\n",
    "        speccases_here = val.split(\",\")\n",
    "\n",
    "        Nspeccases_here = len(speccases_here)\n",
    "        Nbadspecs = 0 # counting bad/missing specs for this analysis\n",
    "        for ispeccases_here in range(Nspeccases_here): # loop over all measure requirements associated with this Specific Analysis\n",
    "            speccase_here = (speccases_here[ispeccases_here]).strip() # remove leading whitespace\n",
    "            # look for match with list of specs read in earlier\n",
    "            # if it's present, combine with existing data for this requirement -- how?\n",
    "            # for now: try smallest number\n",
    "            specres_here = 2.0*LARGENUM*np.ones(Nmissions)\n",
    "            try:\n",
    "                specidx = speclist.index(speccase_here)\n",
    "                specres_here = specarray[specidx,:]\n",
    "            except ValueError:\n",
    "                print(\"specification \",speccase_here,\" not generated by earlier Notebook! Ignoring\")\n",
    "                Nbadspecs = Nbadspecs + 1\n",
    "           \n",
    "            #bestspecres_here = np.minimum(bestspecres_here,specres_here)\n",
    "            bestspecres_here = np.fmin(bestspecres_here,specres_here) # get minimum over all non-NaN values\n",
    "\n",
    "        #print(\"For this requirement, the best spec results for each detector are \",bestspecres_here)\n",
    "        if Nbadspecs<Nspeccases_here:\n",
    "            newdata[i,:] = bestspecres_here\n",
    "            useAnalysis[i] = True\n",
    "            \n",
    "        # This is a Ndetectors-length array for this particular Specific Analysis\n",
    "        \n",
    "    # Want to cut the main analysis list down using the useAnalysis array\n",
    "    goodAnalysisCodes=analysisCodes[useAnalysis]\n",
    "    goodAnalysisData=newdata[useAnalysis,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the observations and assessment\n",
    "We first compute the SNR and then the angular resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adfnew = pd.DataFrame(newdata,index=analysisCodes,columns=missionNames)\n",
    "adfnew = pd.DataFrame(goodAnalysisData,index=goodAnalysisCodes,columns=missionNames)\n",
    "print(adfnew)\n",
    "\n",
    "#adf=adf.dropna()\n",
    "def shrink():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"6pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")])\n",
    "]\n",
    "def zoom():\n",
    "    return [\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])\n",
    "]\n",
    "\n",
    "\n",
    "s=adfnew.style.background_gradient(vmin=0.1,vmax=10,cmap='RdYlGn_r').set_properties(**{'max-width': '120px', 'font-size': '6pt'})\n",
    "#s=s.set_table_styles(shrink()+zoom())\n",
    "s=s.set_caption(\"Net performance\")\n",
    "display(s)\n",
    "\n",
    "saveSpecificAnalysesTable=True\n",
    "if saveSpecificAnalysesTable:\n",
    "    outimagename = datadir+'ScoredRequirements_net_'+dates+'.png'\n",
    "    dfi.export(\n",
    "        s,\n",
    "        outimagename\n",
    "    )\n",
    "\n",
    "if True:\n",
    "    dates = date.today().strftime(\"%Y_%m_%d\")\n",
    "    outfile=datadir+'ScoredRequirements_net_'+dates+'.csv'\n",
    "    #adfnew.to_csv(outfile,index=False)\n",
    "    adfnew.to_csv(outfile,index=True)\n",
    "    print('Wrote to file:',outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot sensitivity curves and waveform\n",
    "Here we scale the waveform by delta-f, which is probably not quite right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
