{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation Targets Assessor\n",
    "This notebook aims to ingest a table of source/observation specs with their achievability rating per detector model (as generated by prior notebook), and convolve with the Science STM objectives, each of which involves one or more of those source/observation specs. The output should be a similar table to the input, but with the source/observvation specs replaced by objectives.\n",
    "\n",
    "To run this on Google Colab:\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnGBaker/GWI-metrics/blob/main/Notebooks/STM_Science_Assessor.ipynb)\n",
    "\n",
    "### Some basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !git clone https://github.com/JohnGBaker/GWI-metrics.git\n",
    "    src='GWI-metrics/src/'\n",
    "else:\n",
    "    src='../src/'\n",
    "!mkdir -p '../plots/'\n",
    "\n",
    "# Import\n",
    "import os\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(src)\n",
    "import constants\n",
    "import metrics\n",
    "import sources\n",
    "import concepts\n",
    "import subsystems\n",
    "import background\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import re\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from astropy import units as u\n",
    "\n",
    "LARGENUM = 1.0e10 # This is a hard-coded number to beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the set of concepts\n",
    "Here we load in a set of the pre-defined concepts, or you can define your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "missionNames = (\n",
    "    'LISACBE',\n",
    "    'LISASciRDv1',\n",
    "    'TwinLISA',\n",
    "    'LISAGrande',\n",
    "    'LISAU',\n",
    "    'GoBIGLISA',\n",
    "    'ALIA',\n",
    "    'ALIAlowL')\n",
    "missions=[concepts.menu[mission] for mission in missionNames]\n",
    "\n",
    "Nmissions = len(missionNames)\n",
    "\n",
    "for mission in missions:\n",
    "    mission=background.add2model(mission)\n",
    "#model = concepts.LISACBE.copy()\n",
    "#modelName = model.get('label')\n",
    "#model = background.add2model(model)     # add galactic background model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the observation target data\n",
    "Load information about the target sources and the observation quality targets from the STM.\n",
    "The data are from https://nasa.sharepoint.com/:x:/t/GravitationalWaveImager/EaaeMC7L-2NJpFCQloYbSnoBDZag_cvFWR5_BjRoFAD6Tw?e=uWr4mU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent specs file is: ../Data/ScoredObservations_res_2022_09_09.csv\n",
      "specs are:  ['1.1.b', '1.1.c', '1.1.d', '1.1.e', '1.1.f', '1.1.g', '1.1.h', '1.1.i', '1.2.b', '1.2.c', '1.2.d', '1.2.e', '1.3.b', '1.3.c', '1.3.d', '1.3.e', '1.3.f', '1.3.g', '2.1.a', '2.1.b', '2.1.c', '2.1.d', '2.1.e', '2.1.f', '2.2.b', '2.3.b', '2.3.c', '3.1.a', '3.1.b', '3.2.a', '3.2.b', '3.3.a', '3.3.b', '3.3.c', '3.3.d', '3.3.e', '3.3.f', '3.4.a', '3.4.b', '3.5.a', '3.6.a', '4.1.a', '4.1.b', '4.1.c', '4.1.d', '5.1.a', '5.1.b', '5.1.c', '5.1.d', '5.1.e', '5.2.a', '5.2.b', '5.2.d', '5.3.a', '5.3.b', '5.3.d', '5.4.a', '5.4.b', '5.4.d', '5.5.a', '5.5.b', '5.5.c', '5.6.a', '5.6.b', '5.7.a', '5.7.b']\n"
     ]
    }
   ],
   "source": [
    "# Read in the most recent spec file produced by other Notebook:\n",
    "datadir='../Data/'\n",
    "files=glob(datadir+'ScoredObservations_res_*.csv')\n",
    "files.sort(key=os.path.getmtime)\n",
    "specfile=files[-1]\n",
    "print('Most recent specs file is:',specfile)\n",
    "\n",
    "# Are objective names actually stored?\n",
    "# A: not originally -- had to re-run earlier notbook with the \"index=None\" removed from the CVS save command\n",
    "\n",
    "speclist = []\n",
    "with open(specfile) as f:\n",
    "    for row in f:\n",
    "        speclist.append(row.split(\",\")[0])\n",
    "\n",
    "speclist.pop(0) # remove the top item, which is empty \"corner\" element of table\n",
    "print(\"specs are: \",speclist)\n",
    "\n",
    "Nspecs = len(speclist)\n",
    "\n",
    "#specarray = np.loadtxt(specfile,delimiter=',',skiprows=1,usecols = range(1,Nmissions+1))\n",
    "\n",
    "rawspecarray = np.genfromtxt(specfile,delimiter=',')\n",
    "\n",
    "specarray=rawspecarray[1:Nspecs+1,1:Nmissions+1]\n",
    "#print(\"first row of specarray is \",specarray[0,])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science STM file is: ../Data/ScienceSTM-09-09-22.csv\n",
      "74 rows read from file.\n",
      "requirement Names are  ['2.1.b, 2.3.b' '1.1.f' '1.2.c' nan '1.3.g' nan nan '2.1.f, 2.3.c' '1.3.f'\n",
      " '1.1.g' '1.2.d' '4.1.e' '3.1.b, 3.2.b, 3.3.f, 3.4.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b' nan nan '1.1.h' '1.2.e'\n",
      " nan nan nan nan '1.1.i' nan '2.1.c, 2.1.d, 2.1.e' '1.3.c, 1.3.d, 1.3.e'\n",
      " '1.1.c, 1.1.d, 1.1.e' nan '4.1.c, 4.1.d' nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan 'SNR O(1000)' '5.5.c' nan nan nan\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)' nan '3.3.a' nan\n",
      " '2.1.a, 2.1.b, 2.1.c, 2.3.a, 2.3.b' '2.1.a, 2.1.b, 2.1.c'\n",
      " '2.1.a, 2.1.b, 2.1.d, 2.3.a' '3.3.c, 3.3.e' '3.3.b' '3.5.a' '3.6.a'\n",
      " '5.5.a, 5.6.a' nan nan nan '3.4.a' nan nan nan nan nan]\n",
      "analyses are:  ['1a-1a: Perform waveform analysis of MBHB mergers to determine distance.'\n",
      " '1a-1b: BNS mergers' '1a-1c: NS-BH' '1a-1d: EMRI (TDE)'\n",
      " '1a-1e: WD-WD -> Type 1a SN (feasible?)' '1a-1f: IMRI (IMBH-WD (?))'\n",
      " '1a-1g: EMRI (MBH-WD)'\n",
      " '1a-2a: Perform waveform analysis of MBH binary systems to determine distance and localize to host galaxy with high angular precision.'\n",
      " '1a-2b:SOBH binaries' '1a-2c: BNS' '1a-2d: NS-BH' '1a-2e: WD binary'\n",
      " '1a-2f: EMRI' '1a-2g: IMRI'\n",
      " '1a-3a: Posterior (statistical) analyses of populations of GW systems in comparison with astronomical catalogs'\n",
      " '1a-3b: SOBH binaries' '1a-3c: BNS' '1a-3d: NS-BH' '1a-3e: WD binary'\n",
      " '1a-3f: EMRI' '1a-3g: IMRI'\n",
      " '1a-4a: Statistical analysis of large numbers of GW systems. Use astrophysical priors to constrain intrinsic luminosity.'\n",
      " '1a-4b: NS-NS' '1a-5a: MBHB'\n",
      " '1b-1a: Identify lensed MBH binary signals (look for events that look the same, but with a time delay; Look for interference between signals that are long duration or that arrive close together in time) '\n",
      " '1b-1b: SOBH binaries' '1b-1c: BNS' '1b-1d: NS-BH' '1b-1e: WD binary'\n",
      " '1b-2f: EMRI' '1b-1g: IMRI'\n",
      " '1b-2a: Perform statistical analysis of MBHB mergers in order to identify sources that appear to be closer than indicated by redshift measurements, indicating systems are weakly lensed. '\n",
      " '1b-2b: MBH binary systems localized to host galaxy'\n",
      " '1b-2c: SOBH binary systems localized to host galaxy'\n",
      " '1b-2d: BNS mergers' '1b-2e: BNS systems localized to host galaxy'\n",
      " '1b-2f: NS-BH mergers' '1b-2g: NS-BH systems localized to host galaxy'\n",
      " '1b-2h: TDE' '1b-2i: MBH-WD' '1b-2j: EMRI localized to host galaxy'\n",
      " '1b-2k: WD-WD -> Type 1a SN (feasible?)'\n",
      " '1b-2l: WD binary systems localized to host galaxy' '1b-2m: IMBH-WD (?)'\n",
      " '1b-2n: IMRIs localized to host galaxy'\n",
      " '1b-2o: Look for an anisotropy in the distance distributions of GW sources across the sky'\n",
      " '1b-3a: Identify signatures in the EMRI waveform associated with the encounters.'\n",
      " '1b-3b: IMRI'\n",
      " '1c-1a: Identify and characterize GW signals from BH binaries prior to merger and compile population statistics.'\n",
      " '1c-2a: Measure the characteristics of GW signals from EMRI sources to identify  companions with masses lower than predicted from astrophysical channels.'\n",
      " '1d-1a: Measuring the characteristics of GW signals for the population of SMBHBs.'\n",
      " '1d-2a: Combine Doppler shifts of individual SOBHB well before merger (localized within host galaxy bulge) in clusters to deduce cluster velocity dispersion (sigma).'\n",
      " '1d-2b: BNS well before merger,  localized within host galaxy bulge'\n",
      " '1d-2c: NS-BH well before merger,  localized within host galaxy bulge'\n",
      " '1d-2d: WD binary systems localized within host galaxy bulge'\n",
      " '1d-2e: EMRI system localized within host galaxy bulge'\n",
      " '1e-1a: Distinguish GW signals from early universe processes from astrophysical GW signals by measuring the spectral index of the stochastic GW background and characterizing its anisotropy.'\n",
      " '2a-1a: Measuring the characteristics of GW signals and measuring the EM signals over multiple frequencies and particle signals in multiple energy bands'\n",
      " '2a-2a: Measuring the characteristics of GW signals'\n",
      " '2a-3a: Study phase evolution of waveform to look for evidence of drag from accretion gas on the binary.'\n",
      " '2b-1a: Measuring the characteristics of GW signals of EMRIs and doing statistical analyses of the population of EMRIs.'\n",
      " '2b-2a: Measuring the characteristics of GW signals of EMRIs'\n",
      " '2b-3a: Measure the characteristics of GW signals of MBH-WD and enable searches for EM counterparts.'\n",
      " '2b-3b: Measure the characteristics of GW signals of MBH-MS* and enable searches for EM counterparts.'\n",
      " '2c-1a: Measure the GW signal characteristics of IMRIs.'\n",
      " '2c-1b: IMBH binary systems'\n",
      " '2d-1a: Identify and characterize GW signals from NS binaries prior to merger and compile population statistics.'\n",
      " '2e-1a: Measure the characteristics of the IMBH+WD GW binary signals (TDE scenario).'\n",
      " '2e-1b: MBH+WD mergers (non-TDE scenario)'\n",
      " '2e-2a: Recognize signatures of triple and many-body systems and measure masses and orbits of these systems. Ultimately cast demographical information and evaluate environment influences or constituent effects'\n",
      " '2f-1a: Search for GW signals from WD mergers associated with Type 1a SNe.'\n",
      " '2f-1b: Measure rate and properties (e.g., masses, frequency, mass of remant if no SN) of WD mergers as a function of redshift.'\n",
      " '2g-1a: WD binaries'\n",
      " '2h-1a: Dual-line coincident sources, e.g.  oscillating NSs in ultra-compact x-ray binaries, GWI would help localize sources to increase confidence in dual-line observations']\n",
      "specification  4.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  2.3.a  not generated by earlier Notebook! Ignoring\n",
      "specification  2.3.a  not generated by earlier Notebook! Ignoring\n"
     ]
    }
   ],
   "source": [
    "STMfiles=glob('../Data/ScienceSTM*.csv')\n",
    "STMfiles.sort(key=os.path.getmtime)\n",
    "file=STMfiles[-1]\n",
    "#file=glob('../Data/ScienceSTM*.csv')[0]\n",
    "print('Science STM file is:',file)\n",
    "\n",
    "#Read file\n",
    "df=pd.read_csv(file,header=1)\n",
    "print(len(df),'rows read from file.')\n",
    "\n",
    "if True:\n",
    "    #Drop empty rows\n",
    "    for i,row in df.iterrows():\n",
    "        if row.isnull().all():\n",
    "            df=df.drop(i)\n",
    "    #Fill empties in first column with values above\n",
    "\n",
    "    nrows = len(df. index) \n",
    "\n",
    "    newdata = np.zeros((nrows,Nmissions))\n",
    "\n",
    "    val=float('nan')\n",
    "    \n",
    "    col='Astrophysical Parameters (Level 1 Measurement Req)'\n",
    "    requirementNames=df[col].values\n",
    "    print(\"requirement Names are \",requirementNames)\n",
    "\n",
    "    analysisVal=float('nan')\n",
    "    analysisCol='Specific Analyses'\n",
    "    analysisNames=df[analysisCol].values\n",
    "\n",
    "    print(\"analyses are: \",analysisNames)\n",
    "    \n",
    "    analysisCodes = analysisNames\n",
    "    for j in range(len(analysisNames)):\n",
    "        analysisName_here = analysisNames[j]\n",
    "        #print(\"this analysis names is \",analysisName_here)\n",
    "        #found = re.search(\"\\w\\w-\\w\\w\",analysisName_here).group(1)\n",
    "        found = re.findall(\"\\w\\w-\\w\\w\",analysisName_here)\n",
    "        #print(\"analysis Name \",analysisName_here,' has code ',found[0])\n",
    "        analysisCodes[j] = found[0]\n",
    "    \n",
    "    for i,row in df.iterrows(): #each row should be a specific analysis in analysisNames\n",
    "        if row.isnull()[col]:\n",
    "            df.loc[i,col]=val\n",
    "        else:\n",
    "            val=df.loc[i,col]\n",
    "\n",
    "        if row.isnull()[analysisCol]:\n",
    "            df.loc[i,analysisCol]=analysisVal\n",
    "        else:\n",
    "            analysisVal=df.loc[i,analysisCol]    \n",
    "            \n",
    "        #print(\"this row has astrophysical parameter \",val)\n",
    "\n",
    "        bestspecres_here = LARGENUM*np.ones(Nmissions)\n",
    "\n",
    "        # parse to get values in form of 2.3.b == <single digit> + dot + <single digit> + dot + <single letter>\n",
    "        # or perhaps just a comma-separated list that can be compared with other file\n",
    "        speccases_here = val.split(\",\")\n",
    "\n",
    "        Nspeccases_here = len(speccases_here)\n",
    "        for ispeccases_here in range(Nspeccases_here):\n",
    "            speccase_here = (speccases_here[ispeccases_here]).strip() # remove leading whitespace\n",
    "            # look for match with list of specs read in earlier\n",
    "            # if it's present, combine with existing data for this requirement -- how?\n",
    "            # for now: try smallest number\n",
    "            specres_here = 2.0*LARGENUM*np.ones(Nmissions)\n",
    "            try:\n",
    "                specidx = speclist.index(speccase_here)\n",
    "                specres_here = specarray[specidx,:]\n",
    "            except ValueError:\n",
    "                print(\"specification \",speccase_here,\" not generated by earlier Notebook! Ignoring\")\n",
    "           \n",
    "            bestspecres_here = np.minimum(bestspecres_here,specres_here)\n",
    "\n",
    "        #print(\"For this requirement, the best spec results for each detector are \",bestspecres_here)\n",
    "        newdata[i,:] = bestspecres_here\n",
    "        # This is a Ndetectors-length array for this particular Specific Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the observations and assessment\n",
    "We first compute the SNR and then the angular resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           LISACBE  LISASciRDv1     TwinLISA  LISAGrande       LISAU  \\\n",
      "1a-1a          NaN          NaN          NaN         NaN         NaN   \n",
      "1a-1b     8.158858    11.795723     4.730925    9.487166   19.924074   \n",
      "1a-1c     2.080454     3.007830     1.203882    2.410159    5.043256   \n",
      "1a-1d     2.080454     3.007830     1.203882    2.410159    5.043256   \n",
      "1a-1e    57.974865    83.817546    33.575015   67.636787  141.723589   \n",
      "...            ...          ...          ...         ...         ...   \n",
      "2e-2a  1891.152825  2205.809692  1062.167691  236.535722  237.619668   \n",
      "2f-1a  1891.152825  2205.809692  1062.167691  236.535722  237.619668   \n",
      "2f-1b  1891.152825  2205.809692  1062.167691  236.535722  237.619668   \n",
      "2g-1a  1891.152825  2205.809692  1062.167691  236.535722  237.619668   \n",
      "2h-1a  1891.152825  2205.809692  1062.167691  236.535722  237.619668   \n",
      "\n",
      "       GoBIGLISA         ALIA     ALIAlowL  \n",
      "1a-1a   0.000646     7.999477     6.788416  \n",
      "1a-1b   0.407387     0.446781     0.447112  \n",
      "1a-1c   0.102959     0.119760     0.119849  \n",
      "1a-1d   0.102959     0.119760     0.119849  \n",
      "1a-1e   2.890832     3.004505     3.006737  \n",
      "...          ...          ...          ...  \n",
      "2e-2a  33.301548  1674.145206  1446.460366  \n",
      "2f-1a  33.301548  1674.145206  1446.460366  \n",
      "2f-1b  33.301548  1674.145206  1446.460366  \n",
      "2g-1a  33.301548  1674.145206  1446.460366  \n",
      "2h-1a  33.301548  1674.145206  1446.460366  \n",
      "\n",
      "[74 rows x 8 columns]\n",
      "Wrote to file: ../Data/ScoredRequirements_res_2022_09_09.csv\n"
     ]
    }
   ],
   "source": [
    "#adfnew = pd.DataFrame(newdata,index=requirementNames,columns=missionNames)\n",
    "adfnew = pd.DataFrame(newdata,index=analysisCodes,columns=missionNames)\n",
    "\n",
    "print(adfnew)\n",
    "\n",
    "#adf=adf.dropna()\n",
    "def shrink():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"6pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")])\n",
    "]\n",
    "def zoom():\n",
    "    return [\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])\n",
    "]\n",
    "\n",
    "\n",
    "s=adfnew.style.background_gradient(vmin=0.1,vmax=10,cmap='RdYlGn_r').set_properties(**{'max-width': '120px', 'font-size': '6pt'})\n",
    "s=s.set_table_styles(shrink()+zoom())\n",
    "s=s.set_caption(\"Net performance\")\n",
    "#display(s)\n",
    "\n",
    "if True:\n",
    "    dates = date.today().strftime(\"%Y_%m_%d\")\n",
    "    outfile=datadir+'ScoredRequirements_res_'+dates+'.csv'\n",
    "    adfnew.to_csv(outfile,index=False)\n",
    "    print('Wrote to file:',outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot sensitivity curves and waveform\n",
    "Here we scale the waveform by delta-f, which is probably not quite right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
