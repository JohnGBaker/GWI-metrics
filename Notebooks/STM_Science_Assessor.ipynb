{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation Targets Assessor\n",
    "This notebook aims to ingest a table of source/observation specs with their achievability rating per detector model (as generated by prior notebook), and convolve with the Science STM objectives, each of which involves one or more of those source/observation specs. The output should be a similar table to the input, but with the source/observvation specs replaced by objectives.\n",
    "\n",
    "To run this on Google Colab:\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnGBaker/GWI-metrics/blob/main/Notebooks/STM_Science_Assessor.ipynb)\n",
    "\n",
    "### Some basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !git clone https://github.com/JohnGBaker/GWI-metrics.git\n",
    "    src='GWI-metrics/src/'\n",
    "else:\n",
    "    src='../src/'\n",
    "!mkdir -p '../plots/'\n",
    "\n",
    "# Import\n",
    "import os\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(src)\n",
    "import constants\n",
    "import metrics\n",
    "import sources\n",
    "import concepts\n",
    "import subsystems\n",
    "import background\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import re\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from astropy import units as u\n",
    "\n",
    "LARGENUM = 1.0e10 # This is a hard-coded number to beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the set of concepts\n",
    "Here we load in a set of the pre-defined concepts, or you can define your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "missionNames = (\n",
    "    'LISACBE',\n",
    "    'LISASciRDv1',\n",
    "    'TwinLISA',\n",
    "    'LISAGrande',\n",
    "    'LISAU',\n",
    "    'GoBIGLISA',\n",
    "    'ALIA',\n",
    "    'ALIAlowL')\n",
    "missions=[concepts.menu[mission] for mission in missionNames]\n",
    "\n",
    "Nmissions = len(missionNames)\n",
    "\n",
    "for mission in missions:\n",
    "    mission=background.add2model(mission)\n",
    "#model = concepts.LISACBE.copy()\n",
    "#modelName = model.get('label')\n",
    "#model = background.add2model(model)     # add galactic background model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the observation target data\n",
    "Load information about the target sources and the observation quality targets from the STM.\n",
    "The data are from https://nasa.sharepoint.com/:x:/t/GravitationalWaveImager/EaaeMC7L-2NJpFCQloYbSnoBDZag_cvFWR5_BjRoFAD6Tw?e=uWr4mU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent specs file is: ../Data/ScoredObservations_res_2022_06_21.csv\n",
      "specs are:  ['1.1.b', '1.1.c', '1.1.d', '1.1.e', '1.2.b', '1.3.b', '1.3.c', '1.3.d', '1.3.e', '2.1.a', '2.1.b', '2.1.c', '2.1.d', '2.1.e', '2.2.b', '2.3.b', '3.1.a', '3.2.a', '3.2.b', '3.3.a', '3.3.b', '3.3.c', '3.3.d', '3.3.e', '3.4.a', '4.1.a', '4.1.b', '4.1.c', '4.1.d', '5.1.a', '5.1.b', '5.1.c', '5.1.d', '5.2.a', '5.2.b', '5.3.a', '5.3.b', '5.4.a', '5.4.b', '5.5.a', '5.5.b', '5.5.c', '5.6.a']\n"
     ]
    }
   ],
   "source": [
    "# Read in the most recent spec file produced by other Notebook:\n",
    "datadir='../Data/'\n",
    "files=glob(datadir+'ScoredObservations_res_*.csv')\n",
    "files.sort(key=os.path.getmtime)\n",
    "specfile=files[-1]\n",
    "print('Most recent specs file is:',specfile)\n",
    "\n",
    "# Are objective names actually stored?\n",
    "# A: not originally -- had to re-run earlier notbook with the \"index=None\" removed from the CVS save command\n",
    "\n",
    "speclist = []\n",
    "with open(specfile) as f:\n",
    "    for row in f:\n",
    "        speclist.append(row.split(\",\")[0])\n",
    "\n",
    "speclist.pop(0) # remove the top item, which is empty \"corner\" element of table\n",
    "print(\"specs are: \",speclist)\n",
    "\n",
    "Nspecs = len(speclist)\n",
    "\n",
    "#specarray = np.loadtxt(specfile,delimiter=',',skiprows=1,usecols = range(1,Nmissions+1))\n",
    "\n",
    "rawspecarray = np.genfromtxt(specfile,delimiter=',')\n",
    "\n",
    "specarray=rawspecarray[1:Nspecs+1,1:Nmissions+1]\n",
    "#print(\"first row of specarray is \",specarray[0,])\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science STM file is: ../Data/ScienceSTM-21-Jun-23.csv\n",
      "77 rows read from file.\n",
      "requirement Names are  ['2.1.b' '2.3.b' '1.1.f' '1.2.c' nan nan nan nan '2.1.f, 2.3.c' '1.3.f'\n",
      " '1.1.g' '1.2.d' '4.1.e' '3.1.b, 3.2.b, 3.3.f, 3.4.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b' nan nan nan nan nan nan\n",
      " nan nan nan '2.1.c, 2.1.d, 2.1.e' '1.3.c, 1.3.d, 1.3.e'\n",
      " '1.1.c, 1.1.d, 1.1.e' nan '4.1.c, 4.1.d' nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan 'SNR O(1000)' '5.5.c' nan nan nan\n",
      " '0.11 Hz -> 0.22 Hz, (find merger-time SNR requirement); 1.3.a (?)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '0.5 Hz -> 1.0 Hz (find merger-time SNR requirement)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '0.29 Hz -> 0.58 Hz,  (find merger-time SNR requirement)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)' nan nan nan\n",
      " '2.1.a, 2.1.b, 2.1.c, 2.3.a, 2.3.b' '2.1.a, 2.1.b, 2.1.c'\n",
      " '2.1.a, 2.1.b, 2.1.d, 2.3.a'\n",
      " '3.3.c (less pessimistic model), 3.3.e (more pessimistic model)' '3.3.b'\n",
      " nan nan '5.5.a, 5.6.a' nan nan nan '3.4.a' nan nan nan nan nan]\n",
      "analyses are:  ['1a-1a: Perform waveform analysis of MBHB mergers to determine distance.'\n",
      " nan '1a-1b: BNS mergers' '1a-1c: NS-BH' '1a-1d: TDE'\n",
      " '1a-1e: WD-WD -> Type 1a SN (feasible?)' '1a-1f: IMBH-WD (?)'\n",
      " '1a-1g: MBH-WD'\n",
      " '1a-2a: Perform waveform analysis of MBH binary systems to determine distance and localize to host galaxy with high angular precision.'\n",
      " '1a-2b:SOBH binaries' '1a-2c: BNS' '1a-2d: NS-BH' '1a-2e: WD binary'\n",
      " '1a-2f: EMRI' '1a-2g: IMRI'\n",
      " '1a-3a: Posterior (statistical) analyses of populations of GW systems in comparison with astronomical catalogs'\n",
      " '1a-3b: SOBH binaries' '1a-3c: BNS' '1a-3d: NS-BH' '1a-3e: WD binary'\n",
      " '1a-3f: EMRI' '1a-3g: IMRI'\n",
      " '1a-4a: Statistical analysis of large numbers of GW systems. Use astrophysical priors to constrain intrinsic luminosity.'\n",
      " '1a-4b: NS-NS'\n",
      " '1b-1a: Identify lensed MBH binary signals (look for events that look the same, but with a time delay; Look for interference between signals that are long duration or that arrive close together in time) '\n",
      " '1b-1: SOBH binaries' '1b-1c: BNS' '1b-1d: NS-BH' '1b-1e: WD binary'\n",
      " '1b-2f: EMRI' '1b-1g: IMRI'\n",
      " '1b-2a: Perform statistical analysis of MBHB mergers in order to identify sources that appear to be closer than indicated by redshift measurements, indicating systems are weakly lensed. '\n",
      " '1b-2b: MBH binary systems localized to host galaxy'\n",
      " '1b-2c: SOBH binary systems localized to host galaxy'\n",
      " '1b-2d: BNS mergers' '1b-2e: BNS systems localized to host galaxy'\n",
      " '1b-2f: NS-BH mergers' '1b-2g: NS-BH systems localized to host galaxy'\n",
      " '1b-2h: TDE' '1b-2i: MBH-WD' '1b-2j: EMRI localized to host galaxy'\n",
      " '1b-2k: WD-WD -> Type 1a SN (feasible?)'\n",
      " '1b-2l: WD binary systems localized to host galaxy' '1b-2m: IMBH-WD (?)'\n",
      " '1b-2n: IMRIs localized to host galaxy'\n",
      " '1b-2o: Look for an anisotropy in the distance distributions of GW sources across the sky'\n",
      " '1b-3a: Identify signatures in the EMRI waveform associated with the encounters.'\n",
      " '1b-3b: IMRI'\n",
      " '1c-1a: Identify and characterize GW signals from BH binaries prior to merger and compile population statistics.'\n",
      " '1c-2a: Measure the characteristics of GW signals from EMRI sources to identify  companions with masses lower than predicted from astrophysical channels.'\n",
      " '1d-1a: Measuring the characteristics of GW signals for the population of SMBHBs.'\n",
      " '1d-2b: Combine Doppler shifts of individual SOBHB mergers (localized within host galaxy bulge) in clusters to deduce cluster velocity dispersion (sigma).'\n",
      " '1d-2c: SOBHB well before merger'\n",
      " '1d-2d: BNS mergers localized within host galaxy bulge'\n",
      " '1d-2e: BNS well before merger'\n",
      " '1d-2f: NS-BH mergers localized within host galaxy bulge'\n",
      " '1d-2g: NS-BH well before merger'\n",
      " '1d-2h: WD binary merger localized within host galaxy bulge'\n",
      " '1d-2i: WD binary systems localized within host galaxy bulge'\n",
      " 'Distinguish GW signals from early universe processes from astrophysical GW signals by measuring the spectral index of the stochastic GW background and characterizing its anisotropy.'\n",
      " '2a-1a: Measuring the characteristics of GW signals and measuring the EM signals over multiple frequencies and particle signals in multiple energy bands'\n",
      " '2a-2a: Measuring the characteristics of GW signals'\n",
      " '2a-3a: Study phase evolution of waveform to look for evidence of drag from accretion gas on the binary.'\n",
      " '2b-1a: Measuring the characteristics of GW signals of EMRIs and doing statistical analyses of the population of EMRIs.'\n",
      " '2b-2a: Measuring the characteristics of GW signals of EMRIs'\n",
      " '2b-3a: Precision modeling of gravitational waveforms of EMRIs.' nan\n",
      " '2c-1a: Measure the GW signal characteristics of IMRIs.'\n",
      " '2c-1b: IMBH binary systems'\n",
      " '2d-1a: Identify and characterize GW signals from NS binaries prior to merger and compile population statistics.'\n",
      " '2e-1a: Measure the characteristics of the MBH+WD GW binary signals.'\n",
      " '2e-1b: MBH+WD mergers'\n",
      " '2e-2a: Recognize signatures of triple and many-body systems and measure masses and orbits of these systems. Ultimately cast demographical information and evaluate environment influences or constituent effects'\n",
      " '2f-1a: Search for GW signals from WD mergers associated with Type 1a SNe.'\n",
      " '2f-1b: Measure rate and properties (e.g., masses, frequency, mass of remant if no SN) of WD mergers as a function of redshift.'\n",
      " '2g-1a: WD binaries' nan]\n",
      "specification  1.1.f  not generated by earlier Notebook! Ignoring\n",
      "specification  1.2.c  not generated by earlier Notebook! Ignoring\n",
      "specification  1.2.c  not generated by earlier Notebook! Ignoring\n",
      "specification  1.2.c  not generated by earlier Notebook! Ignoring\n",
      "specification  1.2.c  not generated by earlier Notebook! Ignoring\n",
      "specification  1.2.c  not generated by earlier Notebook! Ignoring\n",
      "specification  2.1.f  not generated by earlier Notebook! Ignoring\n",
      "specification  2.3.c  not generated by earlier Notebook! Ignoring\n",
      "specification  1.3.f  not generated by earlier Notebook! Ignoring\n",
      "specification  1.1.g  not generated by earlier Notebook! Ignoring\n",
      "specification  1.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  4.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  3.1.b  not generated by earlier Notebook! Ignoring\n",
      "specification  3.3.f  not generated by earlier Notebook! Ignoring\n",
      "specification  3.4.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.1.e  not generated by earlier Notebook! Ignoring\n",
      "specification  5.2.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.3.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.4.d  not generated by earlier Notebook! Ignoring\n",
      "specification  5.6.b  not generated by earlier Notebook! Ignoring\n",
      "specification  5.7.b  not generated by earlier Notebook! Ignoring\n",
      "specification  SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  0.11 Hz -> 0.22 Hz  not generated by earlier Notebook! Ignoring\n",
      "specification  (find merger-time SNR requirement); 1.3.a (?)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  0.5 Hz -> 1.0 Hz (find merger-time SNR requirement)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  0.29 Hz -> 0.58 Hz  not generated by earlier Notebook! Ignoring\n",
      "specification  (find merger-time SNR requirement)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  (choose separation; add frequencies)  not generated by earlier Notebook! Ignoring\n",
      "specification  with SNR O(1000)  not generated by earlier Notebook! Ignoring\n",
      "specification  2.3.a  not generated by earlier Notebook! Ignoring\n",
      "specification  2.3.a  not generated by earlier Notebook! Ignoring\n",
      "specification  3.3.c (less pessimistic model)  not generated by earlier Notebook! Ignoring\n",
      "specification  3.3.e (more pessimistic model)  not generated by earlier Notebook! Ignoring\n"
     ]
    }
   ],
   "source": [
    "file=glob('../Data/ScienceSTM*.csv')[0]\n",
    "print('Science STM file is:',file)\n",
    "#Read file\n",
    "df=pd.read_csv(file,header=1)\n",
    "print(len(df),'rows read from file.')\n",
    "\n",
    "if True:\n",
    "    #Drop empty rows\n",
    "    for i,row in df.iterrows():\n",
    "        if row.isnull().all():\n",
    "            df=df.drop(i)\n",
    "    #Fill empties in first column with values above\n",
    "\n",
    "    nrows = len(df. index) \n",
    "\n",
    "    newdata = np.zeros((nrows,Nmissions))\n",
    "\n",
    "    val=float('nan')\n",
    "    \n",
    "    col='Astrophysical Parameters (Level 1 Measurement Req)'\n",
    "    requirementNames=df[col].values\n",
    "    print(\"requirement Names are \",requirementNames)\n",
    "\n",
    "    analysisVal=float('nan')\n",
    "    analysisCol='Specific Analyses'\n",
    "    analysisNames=df[analysisCol].values\n",
    "\n",
    "    print(\"analyses are: \",analysisNames)\n",
    "    \n",
    "    for i,row in df.iterrows(): #each row should be a specific analysis in analysisNames\n",
    "        if row.isnull()[col]:\n",
    "            df.loc[i,col]=val\n",
    "        else:\n",
    "            val=df.loc[i,col]\n",
    "\n",
    "        if row.isnull()[analysisCol]:\n",
    "            df.loc[i,analysisCol]=analysisVal\n",
    "        else:\n",
    "            analysisVal=df.loc[i,analysisCol]    \n",
    "            \n",
    "        #print(\"this row has astrophysical parameter \",val)\n",
    "\n",
    "        bestspecres_here = LARGENUM*np.ones(Nmissions)\n",
    "\n",
    "        # parse to get values in form of 2.3.b == <single digit> + dot + <single digit> + dot + <single letter>\n",
    "        # or perhaps just a comma-separated list that can be compared with other file\n",
    "        speccases_here = val.split(\",\")\n",
    "\n",
    "        Nspeccases_here = len(speccases_here)\n",
    "        for ispeccases_here in range(Nspeccases_here):\n",
    "            speccase_here = (speccases_here[ispeccases_here]).strip() # remove leading whitespace\n",
    "            # look for match with list of specs read in earlier\n",
    "            # if it's present, combine with existing data for this requirement -- how?\n",
    "            # for now: try smallest number\n",
    "            specres_here = 2.0*LARGENUM*np.ones(Nmissions)\n",
    "            try:\n",
    "                specidx = speclist.index(speccase_here)\n",
    "                specres_here = specarray[specidx,:]\n",
    "            except ValueError:\n",
    "                print(\"specification \",speccase_here,\" not generated by earlier Notebook! Ignoring\")\n",
    "           \n",
    "            bestspecres_here = np.minimum(bestspecres_here,specres_here)\n",
    "\n",
    "        #print(\"For this requirement, the best spec results for each detector are \",bestspecres_here)\n",
    "        newdata[i,:] = bestspecres_here\n",
    "        # This is a Ndetectors-length array for this particular Specific Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the observations and assessment\n",
    "We first compute the SNR and then the angular resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requirement Names are  ['2.1.b' '2.3.b' '1.1.f' '1.2.c' '1.2.c' '1.2.c' '1.2.c' '1.2.c'\n",
      " '2.1.f, 2.3.c' '1.3.f' '1.1.g' '1.2.d' '4.1.e'\n",
      " '3.1.b, 3.2.b, 3.3.f, 3.4.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b'\n",
      " '5.1.e, 5.2.d, 5.3.d, 5.4.d, 5.5.c, 5.6.b, 5.7.b' '2.1.c, 2.1.d, 2.1.e'\n",
      " '1.3.c, 1.3.d, 1.3.e' '1.1.c, 1.1.d, 1.1.e' '1.1.c, 1.1.d, 1.1.e'\n",
      " '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d'\n",
      " '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d'\n",
      " '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d'\n",
      " '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d' '4.1.c, 4.1.d'\n",
      " '4.1.c, 4.1.d' '4.1.c, 4.1.d' 'SNR O(1000)' '5.5.c' '5.5.c' '5.5.c'\n",
      " '5.5.c'\n",
      " '0.11 Hz -> 0.22 Hz, (find merger-time SNR requirement); 1.3.a (?)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '0.5 Hz -> 1.0 Hz (find merger-time SNR requirement)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '0.29 Hz -> 0.58 Hz,  (find merger-time SNR requirement)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '(choose separation; add frequencies), with SNR O(1000)'\n",
      " '2.1.a, 2.1.b, 2.1.c, 2.3.a, 2.3.b' '2.1.a, 2.1.b, 2.1.c'\n",
      " '2.1.a, 2.1.b, 2.1.d, 2.3.a'\n",
      " '3.3.c (less pessimistic model), 3.3.e (more pessimistic model)' '3.3.b'\n",
      " '3.3.b' '3.3.b' '5.5.a, 5.6.a' '5.5.a, 5.6.a' '5.5.a, 5.6.a'\n",
      " '5.5.a, 5.6.a' '3.4.a' '3.4.a' '3.4.a' '3.4.a' '3.4.a' '3.4.a']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mHooks\u001b[0m \u001b[0minto\u001b[0m \u001b[0mJupyter\u001b[0m \u001b[0mnotebook\u001b[0m \u001b[0mrich\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     def render(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, sparse_index, sparse_columns, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0msparse_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"styler.sparse.columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     def set_tooltips(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/style_render.py\u001b[0m in \u001b[0;36m_render_html\u001b[0;34m(self, sparse_index, sparse_columns, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mGenerates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnecessary\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mjinja2\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# TODO: namespace all the pandas keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/style_render.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_todo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, func, axis, subset, **kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;34mf\"Expected shape:   {data.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             )\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36m_update_ctx\u001b[0;34m(self, attrs)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             raise KeyError(\n\u001b[0;32m--> 956\u001b[0;31m                 \u001b[0;34m\"`Styler.apply` and `.applymap` are not compatible \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m                 \u001b[0;34m\"with non-unique index or columns.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             )\n",
      "\u001b[0;31mKeyError\u001b[0m: '`Styler.apply` and `.applymap` are not compatible with non-unique index or columns.'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb6418bd790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to file: ../Data/ScoredRequirements_res_2022_06_23.csv\n"
     ]
    }
   ],
   "source": [
    "adfnew = pd.DataFrame(newdata,index=requirementNames,columns=missionNames)\n",
    "\n",
    "#adf=adf.dropna()\n",
    "def shrink():\n",
    "    return [dict(selector=\"th\",\n",
    "                 props=[(\"font-size\", \"6pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "                 props=[('padding', \"0em 0em\")])\n",
    "]\n",
    "def zoom():\n",
    "    return [\n",
    "            dict(selector=\"th:hover\",\n",
    "                 props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "                 props=[('max-width', '200px'),\n",
    "                        ('font-size', '12pt')])\n",
    "]\n",
    "\n",
    "\n",
    "s=adfnew.style.background_gradient(vmin=0.1,vmax=10,cmap='RdYlGn_r').set_properties(**{'max-width': '120px', 'font-size': '6pt'})\n",
    "s=s.set_table_styles(shrink()+zoom())\n",
    "s=s.set_caption(\"Net performance\")\n",
    "display(s)\n",
    "\n",
    "if True:\n",
    "    dates = date.today().strftime(\"%Y_%m_%d\")\n",
    "    outfile=datadir+'ScoredRequirements_res_'+dates+'.csv'\n",
    "    adfnew.to_csv(outfile,index=False)\n",
    "    print('Wrote to file:',outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot sensitivity curves and waveform\n",
    "Here we scale the waveform by delta-f, which is probably not quite right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
